<!DOCTYPE html>
<html lang="hr-HR">

<head>
    <meta name="description" content="technology,ai">
    <meta name="author" content="Mladen Smrekar Lorem ipsum">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="robots" content="index,follow">
    <meta charset="utf-8">
    <link rel="icon" type="image/png" href="5c85b51b-6f56-4613-a39f-f0b2a272f380.png">
    <link rel="canonical" href="https://www.bug.hr">
    <title>
        Bezvezni tekst
    </title>
</head>

<body>
    <h1 id="vrh">Bezvezni tekst</h1>
    <!-- uvodni odlomak -->
    <p>
        <i>Stanfordov indeks transparentnosti ocijenio je Metu, OpenAI i druge najveće svjetske kompanije koje se bave
            umjetnom inteligencijom prema 100 pokazatelja </i>
    </p>
    <!-- autor -->
    <p>
        <b>Autor:</b> Mladen Smrekar
    </p>

    <br />
    <h2>
        Nijedan glavni programer temeljnih AI modela nije blizu obećane transparentnosti
    </h2>
    <!-- slike se standardno imenuju brend - model - naslov clanka (ne mora bit brend i model, moze bit nesto drugo)-->
    <figure>
        <img src="images/zet-tramvaj-bezvezni-tekst-key-visual-375-281px.jpg" width="1200px" height="800">
        <figcaption>Najnapredniji tramvaj pogonjen umjetnom inteligencijom</figcaption>
    </figure>

    <hr>

    <figure>
        <picture>
            <source media="(min-width:650px)" srcset="zet-tramvaj-bezvezni-tekst-key-visual-375-281px">
            <source media="(min-width:1080px)" srcset="015tmk_2200.jpg">
            <img src="images/zet-tramvaj-bezvezni-tekst-key-visual-375-281px.jpg" width="1200px" height="800">
        </picture>
        <figcaption>Najnapredniji tramvaj pogonjen umjetnom inteligencijom</figcaption>
    </figure>
    <details>
        <summary>Kako ovo radi?</summary>
        <p>E, nije jednostavno.</p>
    </details>
    <details>
        <summary>Dal da kazem hvala?</summary>
        <p>Moze!</p>
    </details>


    <p>
        U srpnju i rujnu ove godine 15 najvećih <abbr title="Artificial Intelligence"><dfn>AI</dfn></abbr> kompanija
        potpisalo je dobrovoljne obveze za upravljanje rizicima koje
        predstavlja umjetna inteligencija. Jedna od njih odnosila se na transparentnost uz obećanje da će dijeliti
        informacije "s industrijom i s vladama, civilnim društvom i akademskom zajednicom", te da će javno izvještavati
        ​​o mogućnostima i ograničenjima svojih AI sustava. Zvuči sjajno, no što je zapravo transparentnost kad se
        govori o moćnim i prilagodljivim modelima kao što su OpenAI-jev GPT-4 ili Googleov PaLM 2?
    </p>
    <h2>
        Sve manje transparentnosti
    </h2>
    <p>
        Odgovor na to pitanje daje nam netom objavljeni izvještaj Stanfordovog centra za istraživanje temeljnih modela
        (CRFM). Deset najvećih takvih modela ocijenjeno je prema 100 različitih pokazatelja, a rezultati su blago rečeno
        nezadovoljavajući. Najveću ukupnu ocjenu na testu dobio je Metin Llama 2. No razloga za slanje nema: Llamina 54
        boda od 100 mogućih u školi bi se smatralo lošom, jedva prolaznom ocjenom.
    </p>
    <h2>
        Faktori transparentnosti
    </h2>
    <p>
        Stotinu metrika transparentnosti uključuje upstream faktore koji se odnose na obuku, zatim informacije o
        svojstvima i funkciji modela te downstream faktore vezane uz distribuciju i upotrebu modela.
    </p>
    <p>
        <q>Nije dovoljno da organizacija bude transparentna kada objavljuje model; stvari bi trebale biti transparentne
            i
            kad je riječ o resursima koji ulaze u taj model, o procjenama mogućnosti tog modela i o tome što se događa
            nakon
            izdavanja"</q>, smatraju istraživači sa Stanforda koji su modele ocijenili prema 100 pokazatelja.
        Pročešljali su sve
        javno dostupne podatke i dali modelima 1 ili 0 za svaki pokazatelj prema unaprijed određenim kriterijima.
    </p>
    <h2>
        Podaci o obuci
    </h2>
    <p>
        Podrijetlo podataka o obuci za temeljne modele postalo je vruća tema, s nekoliko tužbi u kojima se navodi da su
        AI tvrtke nezakonito uključile autorski materijal zaštićen autorskim pravima u svoje skupove podataka za obuku,
        podsjeća IEEE Spectrum. Indeks transparentnosti pokazao je da većina tvrtki nije bila otvorena u vezi sa svojim
        podacima.
    </p>
    <p>
        Model Bloomz tvrtke Hugging Face dobio je najveću ocjenu u ovoj kategoriji, 60 posto; niti jedan drugi modela
        nije postigao rezultat iznad 40 posto, a nekoliko ih je dobilo čistu nulu.
    </p>
    <h2>
        Prešućene informacije
    </h2>
    <p>
        Kompanije su također uglavnom šutjele o temi rada. Na primjer, OpenAI koristi učenje s potkrepljenjem iz
        ljudskih
        povratnih informacija kako bi modele poput GPT-4 naučio koji su odgovori najprikladniji i najprihvatljiviji za
        ljude. Ali većina programera ne objavljuje informacije o tome tko su ti ljudski radnici i koliko su plaćeni, a
        sumnja se i da se taj posao povjerava radnicima s niskim plaćama u zemljama poput Kenije.
    </p>
    <p>
        Tri otvorena modela - Llama 2, Bloomz i Stable Diffusion - trenutno prednjače u transparentnosti, postižući više
        ili jednake ocjene najboljem zatvorenom modelu. No, postoji mnogo kontroverzi oko toga trebaju li uopće tako
        moćni modeli biti otvorenog koda i stoga potencijalno dostupni baš svakome.
    </p>
    <h2>
        Godišnje ažuriranje
    </h2>
    <p>
        Važno je upamtiti da čak i ako je model dobio visoku ocjenu transparentnosti u trenutnom indeksu, to ne bi nužno
        značilo da je uzor vrline umjetne inteligencije. Ako bi tvrtka otkrila da je model treniran na materijalu
        zaštićenom autorskim pravima i da su ga usavršavali radnici s plaćom nižom od minimalne, svejedno bi zaradila
        bodove za transparentnost podataka i rada.
    </p>
    <p>
        Stanfordovi istraživači svoj indeks namjeravaju ažurirati barem jednom godišnje i nadaju se da će njihova
        zapažanja koristiti zakonodavcima prilikom pisanja zakona vezanih uz umjetnu inteligenciju.
    </p>
    <h2></h2>
    Nijedan glavni programer temeljnih AI modela nije blizu obećane transparentnosti
    </h2>
    <p>
        U srpnju i rujnu ove godine 15 najvećih <abbr title="Artificial Intelligence"><dfn>AI</dfn></abbr> kompanija
        potpisalo je dobrovoljne obveze za upravljanje rizicima koje
        predstavlja umjetna inteligencija. Jedna od njih odnosila se na transparentnost uz obećanje da će dijeliti
        informacije "s industrijom i s vladama, civilnim društvom i akademskom zajednicom", te da će javno izvještavati
        ​​o mogućnostima i ograničenjima svojih AI sustava. Zvuči sjajno, no što je zapravo transparentnost kad se
        govori o moćnim i prilagodljivim modelima kao što su OpenAI-jev GPT-4 ili Googleov PaLM 2?
    </p>
    <h2>
        Sve manje transparentnosti
    </h2>
    <p>
        Odgovor na to pitanje daje nam netom objavljeni izvještaj Stanfordovog centra za istraživanje temeljnih modela
        (CRFM). Deset najvećih takvih modela ocijenjeno je prema 100 različitih pokazatelja, a rezultati su blago rečeno
        nezadovoljavajući. Najveću ukupnu ocjenu na testu dobio je Metin Llama 2. No razloga za slanje nema: Llamina 54
        boda od 100 mogućih u školi bi se smatralo lošom, jedva prolaznom ocjenom.
    </p>
    <h2>
        Faktori transparentnosti
    </h2>
    <p>
        Stotinu metrika transparentnosti uključuje upstream faktore koji se odnose na obuku, zatim informacije o
        svojstvima i funkciji modela te downstream faktore vezane uz distribuciju i upotrebu modela.
    </p>


    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec elementum sed libero quis porttitor. Vestibulum
        ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Sed sed faucibus nisl, sollicitudin
        sagittis massa. Sed a orci a metus finibus molestie eu et elit. Class aptent taciti sociosqu ad litora torquent
        per conubia nostra, per inceptos himenaeos. Sed eu aliquam nunc, vel venenatis sapien. Duis semper ligula a diam
        dictum, ac ullamcorper augue volutpat. Aenean sit amet vestibulum metus.</p>

    <p>In sit amet lacinia orci. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.
        Nullam scelerisque, nulla vel imperdiet posuere, leo ex dapibus ex, vitae malesuada risus risus in lorem. Proin
        mollis ligula at congue pharetra. Nulla nibh turpis, sodales ut volutpat non, condimentum id velit. Cras
        ullamcorper orci purus, eu faucibus lacus sagittis eu. Nullam eget sodales est, sit amet tristique quam. Etiam
        sit amet nulla sed nisi semper sagittis a non erat. Integer eu enim sapien.</p>

    <p> Aenean porta maximus nisi vitae tincidunt. Phasellus tempus nibh quis vestibulum luctus. Maecenas at cursus
        turpis. Quisque vehicula, dolor vitae tristique blandit, dui nunc dignissim turpis, quis vestibulum dui tortor
        vitae arcu. Praesent id massa lacinia, hendrerit mi sed, ultricies diam. Fusce vitae suscipit libero. Praesent
        iaculis mi ut est molestie dapibus. In eu est consequat, aliquet orci eu, lobortis erat. Quisque ac est non enim
        aliquam pretium quis sit amet leo.</p>

    <p>Vivamus dapibus euismod leo vitae elementum. Aenean lectus eros, gravida eu placerat a, imperdiet in tellus. Duis
        mollis magna turpis, ut pretium sem finibus vel. Phasellus vitae libero commodo, ultrices eros in, blandit quam.
        Quisque malesuada metus ac lectus maximus bibendum. Etiam molestie lacinia lectus sit amet facilisis. Donec
        lacus urna, egestas mollis urna sit amet, tincidunt finibus nisl. Fusce sollicitudin gravida blandit. Quisque
        molestie sed turpis eget pellentesque. Donec laoreet massa id nunc facilisis accumsan molestie sit amet ex. Cras
        semper pharetra porttitor. Ut sit amet massa massa. Aliquam vel gravida nisi, at volutpat lorem. Quisque
        consequat, est ut vestibulum aliquam, ex neque rhoncus ipsum, nec accumsan justo tellus id metus. Aenean iaculis
        in quam id molestie.</p>

    <p>Duis eu odio scelerisque, efficitur nisi nec, varius dolor. Integer dictum urna eget arcu dapibus, non malesuada
        justo interdum. Phasellus aliquam pharetra turpis sit amet consectetur. Pellentesque vel ante ullamcorper,
        dapibus lacus semper, euismod neque. Cras mollis blandit nisl, vel laoreet purus porttitor vel. Proin vitae ante
        purus. Vivamus eleifend lacus fermentum, maximus velit maximus, elementum est. Maecenas vitae nibh sagittis,
        facilisis mi non, fermentum enim. Nulla gravida nibh a orci egestas, efficitur fringilla ligula convallis. </p>


    <p>
        <q>Nije dovoljno da organizacija bude transparentna kada objavljuje model; stvari bi trebale biti transparentne
            i
            kad je riječ o resursima koji ulaze u taj model, o procjenama mogućnosti tog modela i o tome što se događa
            nakon
            izdavanja"</q>, smatraju istraživači sa Stanforda koji su modele ocijenili prema 100 pokazatelja.
        Pročešljali su sve
        javno dostupne podatke i dali modelima 1 ili 0 za svaki pokazatelj prema unaprijed određenim kriterijima.
    </p>
    <h2>
        Podaci o obuci
    </h2>
    <p>
        Podrijetlo podataka o obuci za temeljne modele postalo je vruća tema, s nekoliko tužbi u kojima se navodi da su
        AI tvrtke nezakonito uključile autorski materijal zaštićen autorskim pravima u svoje skupove podataka za obuku,
        podsjeća IEEE Spectrum. Indeks transparentnosti pokazao je da većina tvrtki nije bila otvorena u vezi sa svojim
        podacima.
    </p>
    <p>
        Model Bloomz tvrtke Hugging Face dobio je najveću ocjenu u ovoj kategoriji, 60 posto; niti jedan drugi modela
        nije postigao rezultat iznad 40 posto, a nekoliko ih je dobilo čistu nulu.
    </p>
    <h2>
        Prešućene informacije
    </h2>
    <p>
        Kompanije su također uglavnom šutjele o temi rada. Na primjer, OpenAI koristi učenje s potkrepljenjem iz
        ljudskih
        povratnih informacija kako bi modele poput GPT-4 naučio koji su odgovori najprikladniji i najprihvatljiviji za
        ljude. Ali većina programera ne objavljuje informacije o tome tko su ti ljudski radnici i koliko su plaćeni, a
        sumnja se i da se taj posao povjerava radnicima s niskim plaćama u zemljama poput Kenije.
    </p>
    <p>
        Tri otvorena modela - Llama 2, Bloomz i Stable Diffusion - trenutno prednjače u transparentnosti, postižući više
        ili jednake ocjene najboljem zatvorenom modelu. No, postoji mnogo kontroverzi oko toga trebaju li uopće tako
        moćni modeli biti otvorenog koda i stoga potencijalno dostupni baš svakome.
    </p>
    <h2>
        Godišnje ažuriranje
    </h2>
    <p>
        Važno je upamtiti da čak i ako je model dobio visoku ocjenu transparentnosti u trenutnom indeksu, to ne bi nužno
        značilo da je uzor vrline umjetne inteligencije. Ako bi tvrtka otkrila da je model treniran na materijalu
        zaštićenom autorskim pravima i da su ga usavršavali radnici s plaćom nižom od minimalne, svejedno bi zaradila
        bodove za transparentnost podataka i rada.
    </p>
    <p>
        Stanfordovi istraživači svoj indeks namjeravaju ažurirati barem jednom godišnje i nadaju se da će njihova
        zapažanja koristiti zakonodavcima prilikom pisanja zakona vezanih uz umjetnu inteligenciju.
    </p>
    <footer><a href="#vrh"><img src="images/iconmonstr-caret-up-circle-filled-16.png"></a></footer>
</body>